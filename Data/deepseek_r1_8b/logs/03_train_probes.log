============================================================
Script: train_sycophancy_probe.py
Model: deepseek_r1_8b
Started: 2025-11-26T18:02:46.850187
Full dataset: True
============================================================

[2025-11-26 18:09:45] Loading hidden states and LLM judge labels...
[2025-11-26 18:09:45] Hidden states shape: (4000, 37, 4096)
[2025-11-26 18:09:45] Model: 36 layers, hidden_dim=4096
[2025-11-26 18:09:45] Extraction methods: ['last_prompt', 'last_response', 'mean_response']
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] Total examples: 4000
[2025-11-26 18:09:45] Sycophantic (LLM judge): 1426 (35.6%)
[2025-11-26 18:09:45] Not sycophantic: 2574
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] TRAINING PROBES: LAST_PROMPT
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45]   embed: train=64.34%, test=64.38%
[2025-11-26 18:09:45]   layer_1: train=64.84%, test=65.25%
[2025-11-26 18:09:45]   layer_2: train=65.53%, test=64.75%
[2025-11-26 18:09:45]   layer_3: train=65.66%, test=64.12%
[2025-11-26 18:09:45]   layer_4: train=65.69%, test=64.62%
[2025-11-26 18:09:45]   layer_5: train=66.28%, test=65.38%
[2025-11-26 18:09:45]   layer_6: train=65.94%, test=64.62%
[2025-11-26 18:09:45]   layer_7: train=65.62%, test=65.00%
[2025-11-26 18:09:45]   layer_8: train=65.84%, test=64.62%
[2025-11-26 18:09:45]   layer_9: train=66.03%, test=65.00%
[2025-11-26 18:09:45]   layer_10: train=65.91%, test=63.62%
[2025-11-26 18:09:45]   layer_11: train=66.75%, test=64.12%
[2025-11-26 18:09:45]   layer_12: train=66.59%, test=65.00%
[2025-11-26 18:09:45]   layer_13: train=66.44%, test=64.25%
[2025-11-26 18:09:45]   layer_14: train=66.53%, test=65.12%
[2025-11-26 18:09:45]   layer_15: train=66.53%, test=64.62%
[2025-11-26 18:09:45]   layer_16: train=67.44%, test=65.88%
[2025-11-26 18:09:45]   layer_17: train=67.34%, test=65.25%
[2025-11-26 18:09:45]   layer_18: train=66.12%, test=66.25%
[2025-11-26 18:09:45]   layer_19: train=66.88%, test=65.88%
[2025-11-26 18:09:45]   layer_20: train=67.56%, test=66.00%
[2025-11-26 18:09:45]   layer_21: train=66.84%, test=65.38%
[2025-11-26 18:09:45]   layer_22: train=66.66%, test=65.75%
[2025-11-26 18:09:45]   layer_23: train=66.91%, test=65.25%
[2025-11-26 18:09:45]   layer_24: train=66.72%, test=65.25%
[2025-11-26 18:09:45]   layer_25: train=67.00%, test=64.50%
[2025-11-26 18:09:45]   layer_26: train=67.34%, test=65.00%
[2025-11-26 18:09:45]   layer_27: train=66.91%, test=65.38%
[2025-11-26 18:09:45]   layer_28: train=66.72%, test=65.25%
[2025-11-26 18:09:45]   layer_29: train=66.53%, test=66.88%
[2025-11-26 18:09:45]   layer_30: train=66.78%, test=66.25%
[2025-11-26 18:09:45]   layer_31: train=66.31%, test=67.25%
[2025-11-26 18:09:45]   layer_32: train=66.25%, test=66.38%
[2025-11-26 18:09:45]   layer_33: train=66.84%, test=68.12%
[2025-11-26 18:09:45]   layer_34: train=66.38%, test=65.50%
[2025-11-26 18:09:45]   layer_35: train=65.97%, test=66.62%
[2025-11-26 18:09:45]   layer_36: train=66.47%, test=65.62%
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] *** BEST LAYER for last_prompt: 33 (test acc: 68.12%) ***
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] TRAINING PROBES: LAST_RESPONSE
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45]   embed: train=64.53%, test=64.12%
[2025-11-26 18:09:45]   layer_1: train=64.81%, test=65.25%
[2025-11-26 18:09:45]   layer_2: train=64.62%, test=65.50%
[2025-11-26 18:09:45]   layer_3: train=65.47%, test=63.75%
[2025-11-26 18:09:45]   layer_4: train=65.12%, test=63.25%
[2025-11-26 18:09:45]   layer_5: train=65.19%, test=62.00%
[2025-11-26 18:09:45]   layer_6: train=65.56%, test=63.12%
[2025-11-26 18:09:45]   layer_7: train=65.47%, test=63.50%
[2025-11-26 18:09:45]   layer_8: train=65.62%, test=62.25%
[2025-11-26 18:09:45]   layer_9: train=65.62%, test=63.38%
[2025-11-26 18:09:45]   layer_10: train=65.91%, test=65.62%
[2025-11-26 18:09:45]   layer_11: train=66.25%, test=66.25%
[2025-11-26 18:09:45]   layer_12: train=66.03%, test=64.75%
[2025-11-26 18:09:45]   layer_13: train=65.69%, test=66.25%
[2025-11-26 18:09:45]   layer_14: train=65.91%, test=64.38%
[2025-11-26 18:09:45]   layer_15: train=66.66%, test=65.50%
[2025-11-26 18:09:45]   layer_16: train=65.81%, test=64.88%
[2025-11-26 18:09:45]   layer_17: train=66.91%, test=65.38%
[2025-11-26 18:09:45]   layer_18: train=65.75%, test=67.50%
[2025-11-26 18:09:45]   layer_19: train=66.50%, test=65.75%
[2025-11-26 18:09:45]   layer_20: train=66.84%, test=66.38%
[2025-11-26 18:09:45]   layer_21: train=66.84%, test=67.25%
[2025-11-26 18:09:45]   layer_22: train=66.03%, test=66.12%
[2025-11-26 18:09:45]   layer_23: train=66.19%, test=65.38%
[2025-11-26 18:09:45]   layer_24: train=65.94%, test=64.50%
[2025-11-26 18:09:45]   layer_25: train=66.88%, test=65.00%
[2025-11-26 18:09:45]   layer_26: train=67.50%, test=64.00%
[2025-11-26 18:09:45]   layer_27: train=66.34%, test=63.75%
[2025-11-26 18:09:45]   layer_28: train=66.16%, test=63.75%
[2025-11-26 18:09:45]   layer_29: train=65.78%, test=65.25%
[2025-11-26 18:09:45]   layer_30: train=66.28%, test=65.38%
[2025-11-26 18:09:45]   layer_31: train=66.56%, test=64.75%
[2025-11-26 18:09:45]   layer_32: train=65.97%, test=65.50%
[2025-11-26 18:09:45]   layer_33: train=66.34%, test=65.88%
[2025-11-26 18:09:45]   layer_34: train=66.59%, test=65.50%
[2025-11-26 18:09:45]   layer_35: train=66.06%, test=65.62%
[2025-11-26 18:09:45]   layer_36: train=66.00%, test=65.88%
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] *** BEST LAYER for last_response: 18 (test acc: 67.50%) ***
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] TRAINING PROBES: MEAN_RESPONSE
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45]   embed: train=69.44%, test=68.88%
[2025-11-26 18:09:45]   layer_1: train=69.81%, test=68.88%
[2025-11-26 18:09:45]   layer_2: train=70.38%, test=68.50%
[2025-11-26 18:09:45]   layer_3: train=71.06%, test=69.88%
[2025-11-26 18:09:45]   layer_4: train=71.41%, test=70.38%
[2025-11-26 18:09:45]   layer_5: train=70.75%, test=69.62%
[2025-11-26 18:09:45]   layer_6: train=70.84%, test=69.00%
[2025-11-26 18:09:45]   layer_7: train=71.12%, test=70.38%
[2025-11-26 18:09:45]   layer_8: train=71.41%, test=70.38%
[2025-11-26 18:09:45]   layer_9: train=71.28%, test=71.12%
[2025-11-26 18:09:45]   layer_10: train=71.38%, test=71.12%
[2025-11-26 18:09:45]   layer_11: train=71.31%, test=71.00%
[2025-11-26 18:09:45]   layer_12: train=71.47%, test=71.38%
[2025-11-26 18:09:45]   layer_13: train=71.81%, test=72.25%
[2025-11-26 18:09:45]   layer_14: train=71.59%, test=70.88%
[2025-11-26 18:09:45]   layer_15: train=72.16%, test=72.12%
[2025-11-26 18:09:45]   layer_16: train=73.19%, test=71.62%
[2025-11-26 18:09:45]   layer_17: train=72.81%, test=69.88%
[2025-11-26 18:09:45]   layer_18: train=73.41%, test=72.00%
[2025-11-26 18:09:45]   layer_19: train=73.28%, test=72.00%
[2025-11-26 18:09:45]   layer_20: train=73.53%, test=72.00%
[2025-11-26 18:09:45]   layer_21: train=73.66%, test=72.88%
[2025-11-26 18:09:45]   layer_22: train=73.91%, test=72.88%
[2025-11-26 18:09:45]   layer_23: train=73.53%, test=73.12%
[2025-11-26 18:09:45]   layer_24: train=72.69%, test=71.75%
[2025-11-26 18:09:45]   layer_25: train=72.56%, test=72.88%
[2025-11-26 18:09:45]   layer_26: train=72.78%, test=71.88%
[2025-11-26 18:09:45]   layer_27: train=72.34%, test=72.38%
[2025-11-26 18:09:45]   layer_28: train=72.00%, test=72.50%
[2025-11-26 18:09:45]   layer_29: train=72.19%, test=72.75%
[2025-11-26 18:09:45]   layer_30: train=72.19%, test=72.62%
[2025-11-26 18:09:45]   layer_31: train=72.25%, test=71.88%
[2025-11-26 18:09:45]   layer_32: train=72.19%, test=71.75%
[2025-11-26 18:09:45]   layer_33: train=72.38%, test=71.88%
[2025-11-26 18:09:45]   layer_34: train=72.25%, test=71.62%
[2025-11-26 18:09:45]   layer_35: train=72.59%, test=71.75%
[2025-11-26 18:09:45]   layer_36: train=72.31%, test=71.50%
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] *** BEST LAYER for mean_response: 23 (test acc: 73.12%) ***
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] COMPARISON OF EXTRACTION METHODS
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] Method               Best Layer   Test Acc    
[2025-11-26 18:09:45] --------------------------------------------
[2025-11-26 18:09:45] last_prompt          33           68.12%      
[2025-11-26 18:09:45] last_response        18           67.50%      
[2025-11-26 18:09:45] mean_response        23           73.12%      
[2025-11-26 18:09:45] --------------------------------------------
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] *** BEST OVERALL: mean_response (layer 23, acc: 73.12%) ***
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] SPARSE PROBE ANALYSIS (mean_response, Layer 23)
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] Non-zero weights: 915/4096 (22.3%)
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] Top 10 neurons PREDICTING sycophancy:
[2025-11-26 18:09:45]   1. Neuron 3397: weight = 0.2443
[2025-11-26 18:09:45]   2. Neuron 153: weight = 0.2077
[2025-11-26 18:09:45]   3. Neuron 2617: weight = 0.1934
[2025-11-26 18:09:45]   4. Neuron 2925: weight = 0.1917
[2025-11-26 18:09:45]   5. Neuron 1715: weight = 0.1867
[2025-11-26 18:09:45]   6. Neuron 1962: weight = 0.1855
[2025-11-26 18:09:45]   7. Neuron 117: weight = 0.1818
[2025-11-26 18:09:45]   8. Neuron 2171: weight = 0.1778
[2025-11-26 18:09:45]   9. Neuron 2924: weight = 0.1741
[2025-11-26 18:09:45]   10. Neuron 2060: weight = 0.1715
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] Top 10 neurons AGAINST sycophancy:
[2025-11-26 18:09:45]   1. Neuron 2886: weight = -0.2490
[2025-11-26 18:09:45]   2. Neuron 516: weight = -0.2113
[2025-11-26 18:09:45]   3. Neuron 2712: weight = -0.1935
[2025-11-26 18:09:45]   4. Neuron 570: weight = -0.1878
[2025-11-26 18:09:45]   5. Neuron 3283: weight = -0.1875
[2025-11-26 18:09:45]   6. Neuron 2437: weight = -0.1858
[2025-11-26 18:09:45]   7. Neuron 320: weight = -0.1857
[2025-11-26 18:09:45]   8. Neuron 231: weight = -0.1778
[2025-11-26 18:09:45]   9. Neuron 2163: weight = -0.1747
[2025-11-26 18:09:45]   10. Neuron 3215: weight = -0.1746
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] SAVING PROBES
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] All probes saved to /root/Syco-Sup/results/deepseek_r1_8b/sycophancy_probes.pkl
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] DONE!
[2025-11-26 18:09:45] ============================================================
[2025-11-26 18:09:45] 
[2025-11-26 18:09:45] Next step: python test_probe_on_eval.py

============================================================
Finished: 2025-11-26T18:09:45.432612
Exit code: 0
============================================================
